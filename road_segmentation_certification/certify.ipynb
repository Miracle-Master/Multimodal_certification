{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13b9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os,shutil,json\n",
    "import argparse\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "from scipy.special import comb\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-ablation_ratio_test\", type=float, default=0.0107)#for randomized_ablation\n",
    "parser.add_argument(\"-ablation_ratio_test1\", type=float, default=0.0161)#for MMCert\n",
    "parser.add_argument(\"-ablation_ratio_test2\", type=float, default=0.0054)#for MMCert\n",
    "parser.add_argument(\"-r1_r2_ratio\", type=int, default=1)#for MMCert\n",
    "parser.add_argument(\"-alpha\", type=float, default=0.001)\n",
    "parser.add_argument(\"-c\", type=float, help=\"number of test samples\", default=58)\n",
    "parser.add_argument(\"-num_ablated_inputs\", type=int, default=100)\n",
    "\n",
    "def plot_tensor_image(tensor_image, batch_idx=0):\n",
    "    # If tensor has more than 2 dimensions, select the batch index\n",
    "    if len(tensor_image.shape) > 2:\n",
    "        tensor_image = tensor_image[batch_idx]\n",
    "    \n",
    "    # Convert tensor to numpy array\n",
    "    image_array = tensor_image.detach().cpu().numpy()\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(image_array, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "def _lower_confidence_bound(NA: int, N: int, alpha: float) -> float:\n",
    "        \"\"\" Returns a (1 - alpha) lower confidence bound on a bernoulli proportion.\n",
    "        This function uses the Clopper-Pearson method.\n",
    "        :param NA: the number of \"successes\"\n",
    "        :param N: the number of total draws\n",
    "        :param alpha: the confidence level\n",
    "        :return: a lower bound on the binomial proportion which holds true w.p at least (1 - alpha) over the samples\n",
    "        \"\"\"\n",
    "        return proportion_confint(NA, N, alpha, method=\"beta\")\n",
    "def get_bound_list(args):\n",
    "    l =[]\n",
    "    for i in range(101):\n",
    "        lower,upper = _lower_confidence_bound(i, args.num_ablated_inputs, args.alpha)\n",
    "        l.append((lower,upper))\n",
    "    return l\n",
    "\n",
    "def get_bounds1(args, counts, bound_list):\n",
    "    bound_array = np.array(bound_list)  # Convert list of tuples to 2D numpy array\n",
    "\n",
    "    # Index into bound_array using counts to fetch the corresponding bounds\n",
    "    lower_bounds = bound_array[counts][:, :, :, 0]\n",
    "    upper_bounds = bound_array[counts][:, :, :, 1]\n",
    "\n",
    "    return lower_bounds, upper_bounds\n",
    "\n",
    "def get_certified_pixels(all_gt,lower_positive,upper_positive,lower_negative,upper_negative):\n",
    "    certified_pixels = np.zeros((58,375,1242))\n",
    "    for k in range(58):\n",
    "        print(k)\n",
    "        for i in range(375):\n",
    "            for j in range(1242):\n",
    "                if all_gt[k][i][j] ==0:\n",
    "                    if lower_negative[k][i][j] > upper_positive[k][i][j]:\n",
    "                        certified_pixels[k][i][j] = 1\n",
    "                    else:\n",
    "                        certified_pixels[k][i][j] = 0\n",
    "                if all_gt[k][i][j] ==1:\n",
    "                    if lower_positive[k][i][j] > upper_negative[k][i][j]:\n",
    "                        certified_pixels[k][i][j] = 1\n",
    "                    else:\n",
    "                        certified_pixels[k][i][j] = 0\n",
    "    return certified_pixels\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_certified_pixels1(all_gt, lower_positive, upper_positive, lower_negative, upper_negative,e1,e2,n1,n2,k1,k2):\n",
    "    # Initialize the tensor with zeros\n",
    "    certified_pixels = np.zeros((58, 375, 1242))\n",
    "    delta = 1-((comb(e1,k1, exact=True)*comb(e2,k2, exact=True))/(comb(n1,k1, exact=True)*comb(n2,k2, exact=True)))\n",
    "    lower_positive= np.array(lower_positive)-delta\n",
    "    upper_positive= np.array(upper_positive)+delta\n",
    "    lower_negative= np.array(lower_negative)-delta\n",
    "    upper_negative= np.array(upper_negative)+delta\n",
    "    # For ground truth values of 0\n",
    "    mask_gt0 = (all_gt == 0)\n",
    "    certified_pixels[mask_gt0] = (lower_negative[mask_gt0] > upper_positive[mask_gt0]).astype(np.float32)\n",
    "\n",
    "    # For ground truth values of 1\n",
    "    mask_gt1 = (all_gt == 1)\n",
    "    certified_pixels[mask_gt1] = (lower_positive[mask_gt1] > upper_negative[mask_gt1]).astype(np.float32)\n",
    "    \n",
    "    return certified_pixels\n",
    "\n",
    "    \n",
    "def calculate_certified_metrics(all_gt, certified_pixels):\n",
    "    # Ensure inputs are torch tensors\n",
    "    all_gt = torch.tensor(all_gt)\n",
    "    certified_pixels = torch.tensor(certified_pixels)\n",
    "\n",
    "    # Calculate True Positives\n",
    "    TP = torch.sum((all_gt == 1) & (certified_pixels == 1))\n",
    "\n",
    "    # Calculate False Negative\n",
    "    FN = torch.sum((all_gt == 1) & (certified_pixels == 0))\n",
    "    # Calculate False Positive\n",
    "    FP = torch.sum((all_gt == 0) & (certified_pixels == 0))\n",
    "    # Calculate True Negative\n",
    "    TN = torch.sum((all_gt == 0) & (certified_pixels == 1))\n",
    "    # Handle the case where TP + FP = 0 to avoid division by zero\n",
    "\n",
    "    # Calculate precision\n",
    "    pixel_accuracy = (TP.float()+TN.float()) / (TP + FN+FP+TN).float()\n",
    "    recall = TP.float() / (TP + FN).float()\n",
    "    precision = TP.float() / (TP + FP).float()\n",
    "    iou = TP.float() / (TP + FP+FN).float()\n",
    "    return pixel_accuracy.item(), recall.item(), precision.item(), iou.item() # return as a scalar\n",
    "\n",
    "def get_alpha_list(args,n1,n2,k1,k2,certification_method=\"MMCert\"):\n",
    "    l =np.ones((25,101))\n",
    "    \n",
    "    for r in range(25):\n",
    "        #print(r)\n",
    "        r1 = r\n",
    "        r2 = args.r1_r2_ratio*r\n",
    "        e1 = n1-r1\n",
    "        e2 = n2-r2\n",
    "        if certification_method==\"MMCert\":\n",
    "            delta = 1-((comb(e1,k1, exact=True)*comb(e2,k2, exact=True))/(comb(n1,k1, exact=True)*comb(n2,k2, exact=True)))\n",
    "        else:\n",
    "            delta = 1-((comb(e1+e2,k1+k2, exact=True))/(comb(n1+n2,k1+k2, exact=True)))\n",
    "        for i in range(101):\n",
    "            alpha = 0.00001\n",
    "            for j in range(50):\n",
    "                lower_positive,upper_positive = _lower_confidence_bound(i, 100, alpha)\n",
    "                lower_negative,upper_negative = _lower_confidence_bound(100-i, 100, alpha)\n",
    "                #print((lower_positive-delta), (upper_negative+delta))\n",
    "                if ((lower_positive-delta) > (upper_negative+delta)) or ((lower_negative-delta) > (upper_positive+delta)):\n",
    "                    alpha = alpha/10\n",
    "                else:\n",
    "                    if j ==0:\n",
    "                        l[r][i]=1\n",
    "                    else:\n",
    "                        l[r][i]=alpha\n",
    "                    break\n",
    "    return l\n",
    "\n",
    "def get_all_alpha1(all_count, all_gt, alpha_list, r):\n",
    "    all_gt = torch.tensor(all_gt)\n",
    "    all_count = torch.tensor(all_count)\n",
    "    # Create a tensor of ones with the same shape as all_count\n",
    "    all_alpha = torch.ones_like(all_count,dtype=torch.float64)\n",
    "    alpha_list = torch.tensor(alpha_list,dtype=torch.float64) \n",
    "    # Mask for where all_gt is 1 and count in all_pred is <= 50\n",
    "    mask1 = (all_gt == 1) & (all_count <= 50)\n",
    "    \n",
    "    # Mask for where all_gt is 0 and count in all_pred is >= 50\n",
    "    mask2 = (all_gt == 0) & (all_count >= 50)\n",
    "    \n",
    "    # Update all_alpha values to 0 where either mask1 or mask2 is true\n",
    "    all_alpha[mask1 | mask2] = 1\n",
    "\n",
    "    # For other values, get from alpha_list\n",
    "    all_alpha[~(mask1 | mask2)] = alpha_list[r][all_count[~(mask1 | mask2)]]\n",
    "    \n",
    "    return all_alpha\n",
    "\n",
    "def get_certified_pixels_adaptive(all_alpha):\n",
    "    total_budget = 0.001\n",
    "    flattened_alpha = all_alpha.view(all_alpha.size(0), -1)\n",
    "\n",
    "    # Sort the flattened tensor along its last dimension\n",
    "    sorted_values, sorted_indices = torch.sort(flattened_alpha, dim=-1)\n",
    "\n",
    "    cumsum_values = torch.cumsum(sorted_values, dim=-1)\n",
    "\n",
    "    # Find the index where the cumulative sum exceeds the total_budget for each row\n",
    "    #print((cumsum_values <= total_budget).sum(dim=-1).tolist())\n",
    "    mask = (cumsum_values <= total_budget)#.sum(dim=-1).tolist()\n",
    "    B = all_alpha.size(0)\n",
    "    certified_pixels = torch.zeros_like(flattened_alpha)\n",
    "\n",
    "    # Using the mask, get the corresponding indices from sorted_indices for each image in the batch\n",
    "    for i in range(B):\n",
    "        retained_indices = sorted_indices[i][mask[i]]\n",
    "        certified_pixels[i].index_fill_(0, retained_indices, 1)\n",
    "    \n",
    "    return certified_pixels.view_as(all_alpha)\n",
    "\n",
    "def get_certified_pixels_holm(all_alpha):\n",
    "    B = all_alpha.size(0)\n",
    "    H = all_alpha.size(1)\n",
    "    W = all_alpha.size(2)\n",
    "    total_budget = 0.001\n",
    "    flattened_alpha = all_alpha.view(all_alpha.size(0), -1)\n",
    "\n",
    "    # Sort the flattened tensor along its last dimension\n",
    "    sorted_values, sorted_indices = torch.sort(flattened_alpha, dim=-1)\n",
    "    adjusted_thresholds = total_budget / (H * W - torch.arange(H * W).float().to(all_alpha.device) + 1)\n",
    "    adjusted_thresholds = adjusted_thresholds.unsqueeze(0).expand_as(sorted_values)\n",
    "\n",
    "\n",
    "    # Find the index where the cumulative sum exceeds the total_budget for each row\n",
    "    #print((cumsum_values <= total_budget).sum(dim=-1).tolist())\n",
    "    mask = sorted_values <= adjusted_thresholds\n",
    "\n",
    "    # Determine the largest index (or rank) for which the p-value is below its adjusted threshold\n",
    "    max_certified_indices = mask.sum(dim=-1) - 1\n",
    "    #print(max_certified_indices)\n",
    "    max_certified_indices[max_certified_indices < 0] = 0\n",
    "    certified_pixels = torch.zeros_like(flattened_alpha)\n",
    "\n",
    "    # Using the identified indices, mark the certified pixels for each image in the batch\n",
    "    for i in range(B):\n",
    "        max_index = max_certified_indices[i].item()\n",
    "        retained_indices = sorted_indices[i, :max_index + 1]\n",
    "        certified_pixels[i].index_fill_(0, retained_indices, 1)\n",
    "\n",
    "    return certified_pixels.view_as(all_alpha)\n",
    "    \"\"\"\n",
    "    certified_pixels = torch.zeros_like(flattened_alpha)\n",
    "\n",
    "    # Using the mask, get the corresponding indices from sorted_indices for each image in the batch\n",
    "    for i in range(B):\n",
    "        retained_indices = sorted_indices[i][mask[i]]\n",
    "        certified_pixels[i].index_fill_(0, retained_indices, 1)\n",
    "    \n",
    "    return certified_pixels.view_as(all_alpha)\n",
    "    \"\"\"\n",
    "args = parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22bdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========MMCert=========\n"
     ]
    }
   ],
   "source": [
    "print(\"========MMCert=========\")\n",
    "n1 = 375*1242\n",
    "n2 = 375*1242\n",
    "k1 = int(n1*args.ablation_ratio_test1)\n",
    "k2 = int(n2*args.ablation_ratio_test2)\n",
    "all_outputs = torch.load(\"output\\\\\"+\"MMCert\"+\"_ablation-ratio-test1=\"+str(args.ablation_ratio_test1)+\"_ablation-ratio-test2=\"+str(args.ablation_ratio_test2)+\"_all_outputs.pth\")\n",
    "all_pred =all_outputs[\"all_pred\"]\n",
    "all_gt = all_outputs[\"all_gt\"]\n",
    "all_pred = torch.stack([torch.stack(tensors) for tensors in all_pred])\n",
    "all_gt = torch.stack([torch.stack(tensors) for tensors in all_gt])\n",
    "all_pred = torch.transpose(all_pred, 0, 1)\n",
    "all_gt = all_gt[0]\n",
    "\n",
    "#print(all_globalacc[0])\n",
    "#print(torch.min(all_iou[0]),torch.max(all_iou[0]))\n",
    "#{\"all_globalacc\":all_globalacc, \"all_pre\":all_pre, \"all_recall\":all_recall, \"all_F_score\":all_F_score, \"all_iou\":all_iou}\n",
    "all_count = torch.sum(all_pred, dim=1)\n",
    "all_predictions = (all_count > 50).int()\n",
    "\n",
    "alpha_list = get_alpha_list(args,n1,n2,k1,k2, certification_method=\"MMCert\")\n",
    "certified_metrics_mmcert = []\n",
    "for r in range(25):\n",
    "    all_alpha = get_all_alpha1(all_count, all_gt, alpha_list,r)\n",
    "    #print(all_alpha)\n",
    "    certified_pixels = get_certified_pixels_holm(all_alpha)\n",
    "    #certified_pixels1 = get_certified_pixels_adaptive(all_alpha)\n",
    "    certified_metrics_mmcert.append(calculate_certified_metrics(all_gt, certified_pixels))\n",
    "    #plot_tensor_image(certified_pixels,2)\n",
    "    print(\"r, pixel_acc, recall, precision,iou\")\n",
    "    print(r,calculate_certified_metrics(all_gt, certified_pixels))\n",
    "    #print(r,calculate_certified_metrics(all_gt, certified_pixels1))\n",
    "certified_metrics_mmcert.append((0,0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"========randomized_ablation=========\")\n",
    "n1 = 375*1242\n",
    "n2 = 375*1242\n",
    "k1 = int(n1*args.ablation_ratio_test)\n",
    "k2 = int(n2*args.ablation_ratio_test)\n",
    "all_outputs = torch.load(\"output\\\\\"+\"randomized_ablation\"+\"_ablation-ratio-test=\"+str(args.ablation_ratio_test)+\"_all_outputs.pth\")\n",
    "all_pred =all_outputs[\"all_pred\"]\n",
    "all_gt = all_outputs[\"all_gt\"]\n",
    "all_pred = torch.stack([torch.stack(tensors) for tensors in all_pred])\n",
    "all_gt = torch.stack([torch.stack(tensors) for tensors in all_gt])\n",
    "all_pred = torch.transpose(all_pred, 0, 1)\n",
    "all_gt = all_gt[0]\n",
    "\n",
    "#print(all_globalacc[0])\n",
    "#print(torch.min(all_iou[0]),torch.max(all_iou[0]))\n",
    "#{\"all_globalacc\":all_globalacc, \"all_pre\":all_pre, \"all_recall\":all_recall, \"all_F_score\":all_F_score, \"all_iou\":all_iou}\n",
    "all_count = torch.sum(all_pred, dim=1)\n",
    "all_predictions = (all_count > 50).int()\n",
    "print(all_pred.shape)\n",
    "\n",
    "alpha_list = get_alpha_list(args,n1,n2,k1,k2, certification_method=\"randomized_ablation\")\n",
    "certified_metrics_ra = []\n",
    "for r in range(25):\n",
    "    all_alpha = get_all_alpha1(all_count, all_gt, alpha_list,r)\n",
    "    #print(all_alpha)\n",
    "    certified_pixels = get_certified_pixels_holm(all_alpha)\n",
    "    #plot_tensor_image(certified_pixels,2)\n",
    "    certified_metrics_ra.append(calculate_certified_metrics(all_gt, certified_pixels))\n",
    "    print(\"r, pixel_acc, recall, precision,iou\")\n",
    "    print(r,calculate_certified_metrics(all_gt, certified_pixels))\n",
    "certified_metrics_ra.append((0,0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79024a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = np.array(certified_metrics_ra)\n",
    "mmcert = np.array(certified_metrics_mmcert)\n",
    "rs = np.arange(0,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b432b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,4))\n",
    "\n",
    "plt.plot( rs,mmcert[:,0], label =  r'MMCert',color =\"red\")\n",
    "#plt.plot( Ts,bagging_recalls, label = 'Bagging Recall',linestyle = '--',color =\"b\")\n",
    "plt.plot( rs,ra[:,0], label =  r'RA',linestyle = '--',color =\"blue\")\n",
    "\n",
    "#plt.plot( Ts,dpa_ind_recalls, label = 'DPA Recall',linestyle = 'dotted',color =\"b\")\n",
    "#plt.plot( Ts,dpa_ind_recalls, label = 'DPA',linestyle = 'dotted',color =\"g\")\n",
    "#plt.plot( Ts,dpa_ind_precisions, label = 'DPA Precisions',linestyle = '-.',color =\"r\")\n",
    "plt.xlabel(r'$r_1$', fontsize=25)\n",
    "plt.ylabel('Certified pixel accuracy', fontsize=22)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',fontsize=20)\n",
    "plt.xlim(0)\n",
    "plt.xlim(xmax =6)\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "#plt.xticks([0,10,20,30,40,50,60])\n",
    "plt.xticks([0,5,10,15,20,25])\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "#plt.tight_layout()\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figs/'+\"pixel_accuracy\"+'_r1-r2-ratio='+str(args.r1_r2_ratio)+'.pdf', dpi=1000,bbox_inches='tight')\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (7,4))\n",
    "\n",
    "plt.plot( rs,mmcert[:,1], label =  r'MMCert',color =\"red\")\n",
    "#plt.plot( Ts,bagging_recalls, label = 'Bagging Recall',linestyle = '--',color =\"b\")\n",
    "plt.plot( rs,ra[:,1], label =  r'RA',linestyle = '--',color =\"blue\")\n",
    "\n",
    "#plt.plot( Ts,dpa_ind_recalls, label = 'DPA Recall',linestyle = 'dotted',color =\"b\")\n",
    "#plt.plot( Ts,dpa_ind_recalls, label = 'DPA',linestyle = 'dotted',color =\"g\")\n",
    "#plt.plot( Ts,dpa_ind_precisions, label = 'DPA Precisions',linestyle = '-.',color =\"r\")\n",
    "plt.xlabel(r'$r_1$', fontsize=25)\n",
    "plt.ylabel('Certified recall', fontsize=22)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',fontsize=20)\n",
    "plt.xlim(0)\n",
    "plt.xlim(xmax =6)\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "#plt.xticks([0,10,20,30,40,50,60])\n",
    "plt.xticks([0,5,10,15,20,25])\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "#plt.tight_layout()\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figs/'+\"recall\"+'_r1-r2-ratio='+str(args.r1_r2_ratio)+'.pdf', dpi=1000,bbox_inches='tight')\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (7,4))\n",
    "\n",
    "plt.plot( rs,mmcert[:,2], label =  r'MMCert',color =\"red\")\n",
    "#plt.plot( Ts,bagging_recalls, label = 'Bagging Recall',linestyle = '--',color =\"b\")\n",
    "plt.plot( rs,ra[:,2], label =  r'RA',linestyle = '--',color =\"blue\")\n",
    "\n",
    "#plt.plot( Ts,dpa_ind_recalls, label = 'DPA Recall',linestyle = 'dotted',color =\"b\")\n",
    "#plt.plot( Ts,dpa_ind_recalls, label = 'DPA',linestyle = 'dotted',color =\"g\")\n",
    "#plt.plot( Ts,dpa_ind_precisions, label = 'DPA Precisions',linestyle = '-.',color =\"r\")\n",
    "plt.xlabel(r'$r_1$', fontsize=25)\n",
    "plt.ylabel('Certified precision', fontsize=22)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',fontsize=20)\n",
    "plt.xlim(0)\n",
    "plt.xlim(xmax =6)\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "#plt.xticks([0,10,20,30,40,50,60])\n",
    "plt.xticks([0,5,10,15,20,25])\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "#plt.tight_layout()\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figs/'+\"precision\"+'_r1-r2-ratio='+str(args.r1_r2_ratio)+'.pdf', dpi=1000,bbox_inches='tight')\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (7,4))\n",
    "\n",
    "plt.plot( rs,mmcert[:,3], label =  r'MMCert',color =\"red\")\n",
    "#plt.plot( Ts,bagging_recalls, label = 'Bagging Recall',linestyle = '--',color =\"b\")\n",
    "plt.plot( rs,ra[:,3], label =  r'RA',linestyle = '--',color =\"blue\")\n",
    "\n",
    "#plt.plot( Ts,dpa_ind_recalls, label = 'DPA Recall',linestyle = 'dotted',color =\"b\")\n",
    "#plt.plot( Ts,dpa_ind_recalls, label = 'DPA',linestyle = 'dotted',color =\"g\")\n",
    "#plt.plot( Ts,dpa_ind_precisions, label = 'DPA Precisions',linestyle = '-.',color =\"r\")\n",
    "plt.xlabel(r'$r_1$', fontsize=25)\n",
    "plt.ylabel('Certified IoU', fontsize=22)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',fontsize=20)\n",
    "plt.xlim(0)\n",
    "plt.xlim(xmax =6)\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "#plt.xticks([0,10,20,30,40,50,60])\n",
    "plt.xticks([0,5,10,15,20,25])\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "#plt.tight_layout()\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figs/'+\"iou\"+'_r1-r2-ratio='+str(args.r1_r2_ratio)+'.pdf', dpi=1000,bbox_inches='tight')\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==========vanilla=========\")\n",
    "positive_counts = all_count\n",
    "negative_counts = 100- all_count\n",
    "args.alpha = 0.001/n1\n",
    "print(positive_counts.shape)\n",
    "bound_list = get_bound_list(args)\n",
    "lower_positive, upper_positive = get_bounds1(args,positive_counts,bound_list)\n",
    "lower_negative, upper_negative = get_bounds1(args,negative_counts,bound_list)\n",
    "rs = []\n",
    "CAs = []\n",
    "CAs_baseline = []\n",
    "RANGE=30\n",
    "for r in range(RANGE):\n",
    "    r1 = r\n",
    "    r2 = args.r1_r2_ratio*r\n",
    "    e1 = n1-r1\n",
    "    e2 = n2-r2\n",
    "    certified_pixels= get_certified_pixels1(all_gt,lower_positive,upper_positive,lower_negative,upper_negative,e1,e2,n1,n2,k1,k2)\n",
    "    print(r,calculate_certified_recall(all_gt, certified_pixels))\n",
    "    ca = certified_pixels.sum().item()/(375*1242)/58\n",
    "    #print(r, ca)\n",
    "    CAs.append(ca)\n",
    "    rs.append(r)\n",
    "\n",
    "#certified_pixels= get_certified_pixels1(all_gt,lower_positive,upper_positive,lower_negative,upper_negative,e1,e2,n1,n2,k1,k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_lower_confidence_bound(5, 100, 0.001))\n",
    "print(_lower_confidence_bound(95, 100, 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(certified_pixels.sum().item()/(58*375*1242))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lower_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b12887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
